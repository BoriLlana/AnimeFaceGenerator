{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch     # PyTorch\n",
    "import datasets  # Huggingface Datasets; actual data\n",
    "\n",
    "from IPython.display import display  # image display\n",
    "import matplotlib.pyplot as plt      # image display\n",
    "%matplotlib inline                   \n",
    "import random\n",
    "#Torchvision functions\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms.functional as functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"DrishtiSharma/Anime-Face-Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading all images from dictionary to list\n",
    "#all_images = dataset['train'][:63565]['image']\n",
    "#resizing the first image\n",
    "#resized_image = functional.resize(all_images[0], size=[64])\n",
    "#saving the image to a torch tensor\n",
    "#train_tensor = train_tensor = ToTensor()(resized_image).unsqueeze(0)\n",
    "#for the rest of the images, resize then concatinate to that tensor, using dimension 0.\n",
    "for i in range(27528, len(all_images)):\n",
    "    resized_image = functional.resize(all_images[i], size=[64])\n",
    "    train_tensor = torch.cat((train_tensor,ToTensor()(resized_image).unsqueeze(0)), 0)\n",
    "    #if i%10000 == 0:  #I used these as a sanity check for my loop, ignore\n",
    "    #    print('i = ', i)\n",
    "\n",
    "#Saving the tensor so we dont run the above code multiple times.\n",
    "torch.save(train_tensor, 'images.pt')\n",
    "#If everything went well, we will see a tensor of size [63565, 3, 64, 64]:\n",
    "train_tensor"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
